{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ7CvtMea9Dzlg0euEVleM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frios2020/ETL-MADE-EASY/blob/main/Registro_de_Actuaciones_2016_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ETL Processed paperworks at the Peruvian Consulate in Paterson New Jersey during March 2016 - December 2022.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kIRSk2t82oyE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0I5tkaboWOr"
      },
      "source": [
        "import pandas as pd              # this module helps in processing CSV files\n",
        "import glob                      # this module helps in selecting files \n",
        "from datetime import datetime    # this module helps to manipulate datetime fields \n",
        "from google.colab import drive   # this module helps to connect to google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M79sOYQGKmGu"
      },
      "source": [
        "## Set Paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWBj4hoxKmGv"
      },
      "outputs": [],
      "source": [
        "logfile    = \"logfile.txt\"                                        # all event logs will be stored in this file\n",
        "targetfile = \"transformed_data.csv\"                               # file where transformed data is stored\n",
        "folder     = \"/content/drive/MyDrive/RAW DATA/ACTUACIONES/*.xlsx\" # path in google drive where the files to process are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08JsC9qhDDHp"
      },
      "source": [
        "## Connecting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPYIxceTmaC6"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(folder)\n",
        "print(\"Total number of files: \", len(files))"
      ],
      "metadata": {
        "id": "droUA-6YJYEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in files:\n",
        "  print(x)"
      ],
      "metadata": {
        "id": "CARYdbVjJ6wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract"
      ],
      "metadata": {
        "id": "GZafBcClPyUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # XLS Extract Function"
      ],
      "metadata": {
        "id": "hvoAlTvqQEdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_xls(file_to_process):\n",
        "    dataframe = pd.read_excel(file_to_process, parse_dates=['Fecha Actuación']) # Parametrer parse_dates make \"Fecha Actuacion\" like datetime.\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "-al-hQfNQPaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract():\n",
        "    extracted_data = pd.DataFrame()                           # Create an empty data frame to hold extracted data\n",
        "    for xlsfile in glob.glob(folder):                         # Process all xls files and add in onedataframe using append function.\n",
        "        extracted_data = extracted_data.append(extract_from_xls(xlsfile), ignore_index=True)\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "7uqizLqBQjcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4PZLXD9Dj7q"
      },
      "source": [
        "## Cleaning and transforming data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from numpy import datetime64\n",
        "def transform(data):\n",
        "  data = data.dropna(axis=1,how='all')                                       # Delete columns where all values are NaN.\n",
        "  data['Fecha'] = data['Fecha Actuación'].dt.date                            # Create a field \"fecha\"\n",
        "  data['Hora'] = pd.to_datetime(data['Fecha Actuación']).dt.strftime('%H:%M')# Create a field \"hora\".\n",
        "  data['Anio']=data['Fecha Actuación'].dt.year                               # Create a field \"anio\".\n",
        "  data['Mes']=data['Fecha Actuación'].dt.month                               # Create a field \"mes\".\n",
        "  data['Dia']=data['Fecha Actuación'].dt.dayofweek                           # Create a fiekd \"dia\" Monday is 0 and Sunday is 6\n",
        "  \n",
        "  # Rename columns\n",
        "  data.rename(columns = {'N° Item':'Num_Item', 'Corr. Actuación':'Corr_General',\n",
        "                                 'Fecha Actuación':'Fecha_Actuacion','Nombre del Interesado':'Nombres',\n",
        "                                 'Autoadhesivo Consular':'Autoadhesivo_Consular','Naturaleza del Acto':'Descripcion_Actuacion',\n",
        "                                 'N° Tarifa':'Num_Tarifa','N° Actuación':'Num_Actuacion','Moneda Extranjera $':'Moneda_Extranjera',\n",
        "                                 'Soles Consular S/C':'Soles_Consulares','T. C. Consular':'TC_Consular','Observación':'Observacion'\n",
        "                                 }, inplace = True)\n",
        "  # Fix data types of columns\n",
        "  data['Fecha_Actuacion'] = data['Fecha_Actuacion'].astype('datetime64[m]') # Just hours and minutes.\n",
        "  data['Num_Item']=data.Num_Item.astype(int)\n",
        "  data['Corr_General']=data.Corr_General.astype(int)\n",
        "  data['Autoadhesivo_Consular']=data.Autoadhesivo_Consular.astype(str)\n",
        "  data['Num_Actuacion']=data.Num_Actuacion.astype(int)\n",
        "  data['Moneda_Extranjera']=data.Moneda_Extranjera.astype(int)\n",
        "  data['Soles_Consulares']=data.Soles_Consulares.astype(int)\n",
        "  data['TC_Consular']=data.TC_Consular.astype(int)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "qTiQsgafjnuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "bnNzdzDbxP1u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6fofIjHGTck"
      },
      "source": [
        "def load(targetfile,data_to_load):\n",
        "    data_to_load.to_csv(targetfile, encoding=\"utf-16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging"
      ],
      "metadata": {
        "id": "eZcNaftcyvnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log(message):\n",
        "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
        "    now = datetime.now() # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(\"logfile.txt\",\"a\") as f:\n",
        "        f.write(timestamp + ',' + message + '\\n')"
      ],
      "metadata": {
        "id": "oSS27PoWPXFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytbgHNlcyKRa"
      },
      "source": [
        "## Running ETL Process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Umt7shh6yKRa"
      },
      "outputs": [],
      "source": [
        "log(\"ETL Job Started\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log(\"Extract phase Started\")\n",
        "extracted_data = extract()\n",
        "log(\"Extract phase Ended\")\n",
        "extracted_data"
      ],
      "metadata": {
        "id": "k8LQs--zzK0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "log(\"Transform phase Ended\")\n",
        "transformed_data "
      ],
      "metadata": {
        "id": "_WvRD8LHzNdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log(\"Load phase Started\")\n",
        "load(targetfile,transformed_data)\n",
        "log(\"Load phase Ended\")"
      ],
      "metadata": {
        "id": "rjjacYM2zSBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log(\"ETL Job Ended\")"
      ],
      "metadata": {
        "id": "vavdPaB1zVZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}